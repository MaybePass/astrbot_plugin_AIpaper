import os
import json
import re
import asyncio
import aiohttp
from datetime import datetime
from apscheduler.schedulers.asyncio import AsyncIOScheduler

# å¯¼å…¥ fitz å’Œ feedparserï¼Œä½†ä¸åœ¨ä¸»çº¿ç¨‹ç›´æ¥è°ƒç”¨è€—æ—¶æ“ä½œ
import feedparser
import fitz  # PyMuPDF

from astrbot.api import star, logger
from astrbot.api.event import AstrMessageEvent, MessageEventResult, filter, MessageChain
from astrbot.api.message_components import Plain, Image, Node, Nodes, BaseMessageComponent
from astrbot.api.star import StarTools
from astrbot.core.platform.astr_message_event import MessageSession
from astrbot.core.platform.message_type import MessageType

class Main(star.Star):
    def __init__(self, context: star.Context, config: dict = None):
        super().__init__(context, config)
        if not config:
            config = {}
        self.config = config
        
        # 1. é…ç½®è¯»å–ä¸å¥å£®æ€§æ£€æŸ¥
        self.target_groups = self._parse_target_groups(self.config.get("target_groups"))
        self.push_time = self.config.get("push_time", "09:00")
        self.proxy = self.config.get("proxy", "") or None
        self.extra_message = self.config.get("extra_message", "")
        
        default_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI è®ºæ–‡è§£è¯»åŠ©æ‰‹ã€‚\n\n"
            "è®ºæ–‡æ ‡é¢˜: {title}\n"
            "ä½œè€…: {authors}\n"
            "æ‘˜è¦: {abstract}\n\n"
            "è®ºæ–‡å†…å®¹ç‰‡æ®µ:\n{full_text}\n\n"
            "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºå…¶ä»–å¯’æš„è¯­ï¼š\n\n"
            "## ğŸ’¡ æ ¸å¿ƒåˆ›æ–°ç‚¹\n(ç®€è¦æ¦‚æ‹¬)\n\n"
            "## ğŸ“– è®ºæ–‡æ¦‚è¦\n(é€šä¿—è§£é‡Šè¿™ç¯‡è®ºæ–‡è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Œç”¨äº†ä»€ä¹ˆæ–¹æ³•)\n\n"
            "## ğŸ‘¥ ä½œè€…èƒŒæ™¯\n(æ ¹æ®ä½œè€…å§“åç®€è¦ä»‹ç»å…¶æ‰€å±æœºæ„æˆ–çŸ¥åä»£è¡¨ä½œï¼Œå¦‚æœæ— æ³•ç¡®å®šåˆ™ç•¥è¿‡)\n\n"
            "## ğŸ”¬ å…³é”®ç»“è®º\n(å®éªŒç»“æœæˆ–ç†è®ºè´¡çŒ®)"
        )
        self.prompt_template = self.config.get("prompt_template", default_prompt)

        # 2. æ•°æ®æŒä¹…åŒ–è§„èŒƒ (StarTools.get_data_dir)
        # ä½¿ç”¨æ’ä»¶åä½œä¸ºç›®å½•åï¼ŒAstrBot ä¼šè‡ªåŠ¨åœ¨ data/plugin_data/ ä¸‹åˆ›å»º
        self.data_dir = StarTools.get_data_dir("astrbot_plugin_daily_paper")
        self.history_file = os.path.join(self.data_dir, "history.json")
        self.temp_dir = os.path.join(self.data_dir, "temp")
        
        if not os.path.exists(self.temp_dir):
            os.makedirs(self.temp_dir)
            
        self.history = self._load_history()
        
        # 3. å®šæ—¶ä»»åŠ¡åˆå§‹åŒ–
        self.scheduler = AsyncIOScheduler()
        try:
            hour, minute = map(int, self.push_time.split(":"))
            self.scheduler.add_job(self.run_daily_push, 'cron', hour=hour, minute=minute)
            self.scheduler.start()
            logger.info(f"AIè®ºæ–‡æ¨é€å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨: {self.push_time}, ç›®æ ‡ç¾¤: {self.target_groups}")
        except Exception as e:
            logger.error(f"å®šæ—¶ä»»åŠ¡å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¶é—´æ ¼å¼(HH:MM): {e}")

    def _parse_target_groups(self, config_val):
        """è§£æç›®æ ‡ç¾¤ç»„ï¼Œæ”¯æŒå­—ç¬¦ä¸²æˆ–åˆ—è¡¨"""
        if not config_val:
            return []
        if isinstance(config_val, list):
            return [str(g).strip() for g in config_val]
        if isinstance(config_val, str):
            return [g.strip() for g in re.split(r'[,ï¼Œ]', config_val) if g.strip()]
        return []

    def _load_history(self):
        if os.path.exists(self.history_file):
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                return []
        return []

    def _save_history(self):
        # æ”¾åœ¨åŒæ­¥æ–¹æ³•é‡Œè°ƒç”¨ï¼Œä½†åœ¨å®é™…å†™å…¥æ—¶è€ƒè™‘æ”¾å…¥çº¿ç¨‹æ± ï¼ˆè™½ç„¶å†™å°jsonå¾ˆå¿«ï¼Œä½†ä¸ºäº†æœ€ä½³å®è·µï¼‰
        # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾æ•°æ®é‡ä¸å¤§ã€‚å¦‚æœä¸¥æ ¼éµå¾ªè§„èŒƒï¼š
        # asyncio.create_task(asyncio.to_thread(self._write_history_sync))
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(self.history, f)
        except Exception as e:
            logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

    # --- å¼‚æ­¥/çº¿ç¨‹æ± åŒ…è£…å™¨ ---

    async def _parse_feed_in_thread(self, data):
        return await asyncio.to_thread(feedparser.parse, data)

    async def _process_pdf_in_thread(self, pdf_path, img_path):
        """åœ¨çº¿ç¨‹æ± ä¸­å¤„ç† PDFï¼Œé¿å…é˜»å¡ä¸»å¾ªç¯"""
        def _heavy_work():
            doc = None
            try:
                doc = fitz.open(pdf_path)
                # æå–å‰2é¡µæ–‡æœ¬
                text_content = ""
                for page in doc[:2]: 
                    text_content += page.get_text()
                
                # ç¬¬ä¸€é¡µè½¬å›¾ç‰‡
                page = doc.load_page(0)
                pix = page.get_pixmap(dpi=150)
                pix.save(img_path)
                return text_content
            except Exception as e:
                logger.error(f"Fitz processing error: {e}")
                return None
            finally:
                if doc:
                    doc.close()
        
        return await asyncio.to_thread(_heavy_work)

    # --- æ ¸å¿ƒé€»è¾‘ ---

    async def _call_arxiv_api(self, query_url):
        logger.debug(f"Requesting ArXiv: {query_url}, Proxy: {self.proxy}")
        connector = aiohttp.TCPConnector(ssl=False)
        async with aiohttp.ClientSession(connector=connector) as session:
            try:
                async with session.get(query_url, proxy=self.proxy, timeout=30) as response:
                    if response.status != 200:
                        logger.error(f"ArXiv API error: {response.status}")
                        return None
                    data = await response.text()
                    # ä½¿ç”¨çº¿ç¨‹æ± è§£æ Feed
                    return await self._parse_feed_in_thread(data)
            except Exception as e:
                logger.error(f"Network error fetching arxiv: {e}")
                return None

    async def fetch_latest_paper(self):
        url = "http://export.arxiv.org/api/query?search_query=cat:cs.AI+OR+cat:cs.CV+OR+cat:cs.CL&sortBy=submittedDate&sortOrder=descending&max_results=50"
        feed = await self._call_arxiv_api(url)
        
        if not feed or not feed.entries:
            return None

        for entry in feed.entries:
            paper_id = entry.id.split('/')[-1]
            if paper_id not in self.history:
                return self._parse_entry(entry, paper_id)
        
        logger.warning("æœ€è¿‘ 50 ç¯‡è®ºæ–‡éƒ½å·²æ¨é€è¿‡ã€‚")
        return None

    async def fetch_specific_paper(self, query: str):
        id_pattern = r"(\d{4}\.\d{4,5})"
        match = re.search(id_pattern, query)
        
        url = ""
        if match:
            paper_id = match.group(1)
            url = f"http://export.arxiv.org/api/query?id_list={paper_id}"
        else:
            safe_query = query.replace(" ", "+")
            url = f"http://export.arxiv.org/api/query?search_query=ti:{safe_query}&max_results=1"

        feed = await self._call_arxiv_api(url)
        if not feed or not feed.entries:
            return None
        
        entry = feed.entries[0]
        paper_id = entry.id.split('/')[-1]
        return self._parse_entry(entry, paper_id)

    def _parse_entry(self, entry, paper_id):
        return {
            "id": paper_id,
            "title": entry.title.replace('\n', ' '),
            "summary": entry.summary,
            "authors": [a.name for a in entry.authors],
            "link": entry.link,
            "pdf_link": entry.link.replace("abs", "pdf")
        }

    async def process_pdf(self, pdf_url, paper_id):
        """ä¸‹è½½å¹¶å¤„ç† PDF"""
        pdf_path = os.path.join(self.temp_dir, f"{paper_id}.pdf")
        img_path = os.path.join(self.temp_dir, f"{paper_id}.png")
        
        # å¢å¼º PDF ä¸‹è½½é€»è¾‘ï¼šå¢åŠ  Headersï¼Œå¤„ç†è¶…æ—¶
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        connector = aiohttp.TCPConnector(ssl=False)
        async with aiohttp.ClientSession(connector=connector, headers=headers) as session:
            try:
                logger.info(f"Downloading PDF from: {pdf_url}")
                # å¢åŠ è¶…æ—¶æ—¶é—´åˆ° 90sï¼Œéƒ¨åˆ† PDF ä¸‹è½½è¾ƒæ…¢
                async with session.get(pdf_url, proxy=self.proxy, timeout=90) as resp:
                    if resp.status == 200:
                        # ä½¿ç”¨å¼‚æ­¥æ–‡ä»¶å†™å…¥
                        content = await resp.read()
                        # å†™å…¥æ–‡ä»¶æ˜¯ I/O æ“ä½œï¼Œè™½ç„¶å°æ–‡ä»¶å¯ä»¥æ¥å—ï¼Œä½†å¤§æ–‡ä»¶æœ€å¥½ä¹Ÿæ”¾çº¿ç¨‹æ± 
                        # è¿™é‡Œä¸ºäº†ç®€åŒ–ç›´æ¥å†™ï¼Œå› ä¸ºæ˜¯å†…å­˜ -> ç£ç›˜
                        with open(pdf_path, 'wb') as f:
                            f.write(content)
                        logger.info(f"PDF Downloaded: {len(content)} bytes")
                    else:
                        logger.error(f"PDF download status: {resp.status}")
                        return None, None
            except Exception as e:
                logger.error(f"PDF Download failed: {e}")
                return None, None
        
        # åœ¨çº¿ç¨‹æ± ä¸­å¤„ç† PDF è§£æ
        text_content = await self._process_pdf_in_thread(pdf_path, img_path)
        
        # æ¸…ç† PDF æ–‡ä»¶
        if os.path.exists(pdf_path):
            os.remove(pdf_path)
            
        if not text_content:
            logger.error("PDF parsing returned empty text")
            return None, None
            
        return text_content, img_path

    async def translate_title(self, title):
        provider = self.context.get_using_provider()
        if not provider:
            return title
        
        try:
            prompt = f"Please translate the following scientific paper title into Chinese. Only output the translated title, do not output anything else.\n\nTitle: {title}"
            response = await provider.text_chat(prompt=prompt)
            cn_title = response.completion_text.strip().strip('"').strip("'")
            return cn_title
        except Exception as e:
            logger.warning(f"Title translation failed: {e}")
            return title

    async def get_ai_summary(self, title, abstract, full_text, authors):
        provider = self.context.get_using_provider()
        if not provider:
            return "é”™è¯¯ï¼šæœªé…ç½® AI æ¨¡å‹ã€‚"
            
        full_text_snippet = full_text[:3000]
        authors_str = ", ".join(authors)
        
        prompt = self.prompt_template.format(
            title=title,
            abstract=abstract,
            full_text=full_text_snippet,
            authors=authors_str
        )
        
        try:
            response = await provider.text_chat(prompt=prompt)
            return response.completion_text
        except Exception as e:
            return f"AI è§£è¯»ç”Ÿæˆå¤±è´¥: {e}"

    async def _broadcast_to_groups(self, message_chain: MessageChain):
        """ä½¿ç”¨é€šç”¨æ¥å£å¹¿æ’­åˆ°é…ç½®çš„ç¾¤ç»„"""
        if not self.target_groups:
            return
            
        # è·å–æ‰€æœ‰å¹³å°å®ä¾‹
        platforms = self.context.platform_manager.get_insts()
        
        # ä¼˜å…ˆå¯»æ‰¾ aiocqhttp é€‚é…å™¨ (QQ)ï¼Œå› ä¸ºç›®å‰ä¸»è¦é’ˆå¯¹ QQ ç¾¤
        # å¦‚æœæœªæ¥è¦æ”¯æŒå…¶ä»–å¹³å°ï¼Œè¿™é‡Œéœ€è¦ä¿®æ”¹é€»è¾‘æ¥åŒ¹é…ç¾¤å·æ‰€å±çš„å¹³å°
        target_platform = None
        for p in platforms:
            if p.meta().name == "aiocqhttp" or p.meta().name == "napcat":
                 target_platform = p
                 break
        
        if not target_platform:
            logger.error("æœªæ‰¾åˆ°æ”¯æŒ QQ ç¾¤æ¶ˆæ¯çš„å¹³å°é€‚é…å™¨ (aiocqhttp/napcat)ã€‚")
            return

        platform_id = target_platform.meta().id # å¹³å°å®ä¾‹ID

        for group_id in self.target_groups:
            try:
                logger.info(f"æ­£åœ¨å‘é€åˆ°ç¾¤: {group_id}")
                # æ„é€  UMO å­—ç¬¦ä¸²: platform_id:GroupMessage:group_id
                # æ³¨æ„ï¼šaiocqhttp çš„ session_id é€šå¸¸å°±æ˜¯ group_id
                
                # ä½¿ç”¨ context.send_message å‘é€
                # è¿™éœ€è¦æ„é€ ä¸€ä¸ª MessageSession å¯¹è±¡æˆ–è€…ç¬¦åˆæ ¼å¼çš„å­—ç¬¦ä¸²
                session_str = f"{platform_id}:GroupMessage:{group_id}"
                
                await self.context.send_message(session_str, message_chain)
                
                # é¿å…é£æ§
                await asyncio.sleep(2) 
            except Exception as e:
                logger.error(f"å‘é€åˆ°ç¾¤ {group_id} å¤±è´¥: {e}")

    async def _execute_push(self, paper, target_umo=None, is_manual=False, silent_start=False):
        """æ‰§è¡Œæ¨é€é€»è¾‘"""
        
        # 1. å‘é€æç¤º
        if not silent_start and (is_manual or self.target_groups):
            start_msg = MessageChain([Plain(f"ğŸ“„ æ­£åœ¨è·å–è®ºæ–‡: {paper['title']} ...")])
            if is_manual and target_umo:
                await self.context.send_message(target_umo, start_msg)
            elif not is_manual:
                await self._broadcast_to_groups(start_msg)
        
        # 2. å¤„ç†å†…å®¹ (try-finally ç¡®ä¿æ¸…ç†)
        img_path = None
        try:
            pdf_task = self.process_pdf(paper['pdf_link'], paper['id'])
            trans_task = self.translate_title(paper['title'])
            
            results = await asyncio.gather(pdf_task, trans_task)
            (raw_text, img_path), cn_title = results
            
            if not raw_text or not img_path:
                err_msg = MessageChain([Plain("âš ï¸ PDF ä¸‹è½½æˆ–è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œé…ç½®æˆ–ä»£ç†è®¾ç½®ã€‚")])
                if is_manual and target_umo:
                    await self.context.send_message(target_umo, err_msg)
                elif not is_manual:
                    await self._broadcast_to_groups(err_msg)
                return

            # 3. ç”Ÿæˆæ€»ç»“
            explanation = await self.get_ai_summary(paper['title'], paper['summary'], raw_text, paper['authors'])
            
            # 4. è·å– Bot ID
            try:
                self_uin = self.context.platform_manager.get_insts()[0].client_self_id
            except IndexError:
                self_uin = "10000" 

            display_title = f"{cn_title}\n{paper['title']}"

            # Node 1: è®ºæ–‡é¢„è§ˆ
            node1_content: list[BaseMessageComponent] = [
                Plain(f"ğŸ“„ æ ‡é¢˜:\n{display_title}\n\n"),
                Plain(f"ğŸ‘¥ ä½œè€…: {', '.join(paper['authors'][:3])} et al.\n"),
                Plain(f"ğŸ”— é“¾æ¥: {paper['link']}\n"),
                Image.fromFileSystem(img_path)
            ]
            node1 = Node(name="è®ºæ–‡é¢„è§ˆ", uin=self_uin, content=node1_content)
            
            # Node 2: AI è§£è¯»
            node2_content: list[BaseMessageComponent] = [
                Plain(f"ğŸ¤– AI æ·±åº¦è§£è¯»\n\n{explanation}")
            ]
            node2 = Node(name="AI åŠ©æ‰‹", uin=self_uin, content=node2_content)
            
            all_nodes = [node1, node2]

            # Node 3: é¢å¤–æ¶ˆæ¯
            if self.extra_message and self.extra_message.strip():
                node3_content: list[BaseMessageComponent] = [Plain(self.extra_message)]
                node3 = Node(name="è¡¥å……ä¿¡æ¯", uin=self_uin, content=node3_content)
                all_nodes.append(node3)
            
            # 5. å‘é€æ¶ˆæ¯
            try:
                nodes_component = Nodes(all_nodes)
                forward_msg = MessageChain([nodes_component])
                end_msg = MessageChain([Plain("ğŸ“… ä»Šæ—¥ AI è®ºæ–‡å·²é€è¾¾~")])
                
                if is_manual and target_umo:
                    await self.context.send_message(target_umo, forward_msg)
                    if self.extra_message: # åªæœ‰åœ¨æ‰‹åŠ¨æ¨¡å¼ä¸‹ï¼Œä¸ºäº†ä¸æ‰“æ‰°ï¼Œæˆ‘ä»¬åªåœ¨æœ‰é¢å¤–æ¶ˆæ¯æ—¶æ‰å‘ç¬¬äºŒæ¡ï¼Œæˆ–è€…æ ¹æ®éœ€æ±‚è°ƒæ•´
                         pass # æ‰‹åŠ¨æ¨¡å¼å°±ä¸å‘ "ä»Šæ—¥å·²é€è¾¾" äº†
                elif not is_manual:
                    # å®šæ—¶ä»»åŠ¡å¹¿æ’­
                    await self._broadcast_to_groups(forward_msg)
                    await asyncio.sleep(2)
                    await self._broadcast_to_groups(end_msg)
                
                # è®°å½•å†å²
                if not is_manual:
                    self.history.append(paper['id'])
                    self._save_history()
                
                logger.info(f"è®ºæ–‡ {paper['title']} æ¨é€æˆåŠŸ")
                    
            except Exception as e:
                logger.error(f"æ¶ˆæ¯å‘é€å¤±è´¥ (å°è¯•é™çº§å‘é€): {e}")
                # é™çº§: æ‹†å¼€å‘é€
                fallback_chain = MessageChain([
                    Plain(f"ğŸ“„ {display_title}\n{paper['link']}\n\n"),
                    Image.fromFileSystem(img_path),
                    Plain(f"\n\n{explanation}")
                ])
                if self.extra_message:
                    fallback_chain.chain.append(Plain(f"\n\n{self.extra_message}"))

                if is_manual and target_umo:
                    await self.context.send_message(target_umo, fallback_chain)
                elif not is_manual:
                    await self._broadcast_to_groups(fallback_chain)
                    
        finally:
            # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if img_path and os.path.exists(img_path):
                try:
                    os.remove(img_path)
                except Exception as e:
                    logger.warning(f"æ¸…ç†å›¾ç‰‡å¤±è´¥: {e}")

    async def run_daily_push(self):
        """æ¯æ—¥å®šæ—¶ä»»åŠ¡"""
        logger.info(">>> å¼€å§‹æ‰§è¡Œæ¯æ—¥è®ºæ–‡æ¨é€ä»»åŠ¡")
        
        if not self.target_groups:
            logger.warning("æœªé…ç½®æ¨é€ç›®æ ‡ç¾¤ (target_groups)ï¼Œä»»åŠ¡è·³è¿‡ã€‚")
            return
            
        try:
            paper = await self.fetch_latest_paper()
            if not paper:
                logger.warning("æœªè·å–åˆ°æ–°è®ºæ–‡")
                return
            
            # silent_start=True: ä¸å‘é€â€œæ­£åœ¨è·å–...â€
            await self._execute_push(paper, is_manual=False, silent_start=True)
            
        except Exception as e:
            logger.error(f"å®šæ—¶æ¨é€ä»»åŠ¡å¼‚å¸¸: {e}")

    # --- æŒ‡ä»¤éƒ¨åˆ† ---

    @filter.command("paper_set_group")
    @filter.permission_type(filter.PermissionType.ADMIN)
    async def set_group(self, event: AstrMessageEvent):
        """æ·»åŠ å½“å‰ç¾¤åˆ°æ¨é€åˆ—è¡¨"""
        group_id = event.get_group_id()
        if not group_id:
            yield event.plain_result("è¯·åœ¨ç¾¤èŠä¸­ä½¿ç”¨æ­¤æŒ‡ä»¤ã€‚")
            return

        if group_id in self.target_groups:
             yield event.plain_result("å½“å‰ç¾¤èŠå·²åœ¨æ¨é€åˆ—è¡¨ä¸­ã€‚")
             return

        self.target_groups.append(group_id)
        
        # æ›´æ–°é…ç½®
        plugin_md = self.context.get_registered_star("astrbot_plugin_daily_paper")
        if plugin_md and plugin_md.config:
             # ä¿å­˜ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œé€—å·åˆ†éš”
             plugin_md.config["target_groups"] = ",".join(self.target_groups)
             plugin_md.config.save_config()
        
        yield event.plain_result(f"âœ… å·²æ·»åŠ ç¾¤ {group_id} åˆ°æ¯æ—¥æ¨é€åˆ—è¡¨ã€‚")

    @filter.command("paper_push")
    @filter.permission_type(filter.PermissionType.ADMIN)
    async def push_specific(self, event: AstrMessageEvent, query: str):
        """æ¨é€æŒ‡å®šè®ºæ–‡"""
        if not query:
            yield event.plain_result("è¯·è¾“å…¥è®ºæ–‡é“¾æ¥ã€æ ‡é¢˜æˆ– IDã€‚")
            return

        yield event.plain_result("ğŸ” æ­£åœ¨ ArXiv æ£€ç´¢è®ºæ–‡ä¿¡æ¯...")
        paper = await self.fetch_specific_paper(query)
        
        if not paper:
            yield event.plain_result("âŒ æœªåœ¨ ArXiv ä¸Šæ‰¾åˆ°ç›¸å…³è®ºæ–‡ï¼Œè¯·æ£€æŸ¥è¾“å…¥ã€‚")
            return
            
        target = event.unified_msg_origin
        await self._execute_push(paper, target_umo=target, is_manual=True)

    @filter.command("paper_push_now")
    @filter.permission_type(filter.PermissionType.ADMIN)
    async def push_now(self, event: AstrMessageEvent):
        """ç«‹å³è§¦å‘è‡ªåŠ¨æ¨é€ (æ‰‹åŠ¨æµ‹è¯•)"""
        # ç§»é™¤â€œæ­£åœ¨è§¦å‘...â€å›å¤
        
        paper = await self.fetch_latest_paper()
        if not paper:
            yield event.plain_result("æ²¡æœ‰è·å–åˆ°æ–°çš„å¾…æ¨é€è®ºæ–‡ã€‚")
            return
            
        # is_manual=True, silent_start=False (æ˜¾ç¤ºâ€œæ­£åœ¨è·å–â€)
        await self._execute_push(paper, target_umo=event.unified_msg_origin, is_manual=True, silent_start=False)