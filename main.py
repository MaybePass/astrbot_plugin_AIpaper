import os
import json
import re
import time
import asyncio
import feedparser
import fitz  # PyMuPDF
import aiohttp
from datetime import datetime
from apscheduler.schedulers.asyncio import AsyncIOScheduler

from astrbot.api import star, logger
from astrbot.api.event import AstrMessageEvent, MessageEventResult, filter, MessageChain
from astrbot.api.message_components import Plain, Image, Node, Nodes, BaseMessageComponent
from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import AiocqhttpMessageEvent
from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_platform_adapter import AiocqhttpAdapter

class Main(star.Star):
    def __init__(self, context: star.Context, config: dict = None):
        super().__init__(context, config)
        if not config:
            config = {}
        self.config = config
        
        # é…ç½®è¯»å–
        self.target_groups = self._parse_target_groups(self.config.get("target_groups", ""))
        self.push_time = self.config.get("push_time", "09:00")
        self.proxy = self.config.get("proxy", "")
        if not self.proxy:
            self.proxy = None
        
        # è¯»å–é¢å¤–æ¶ˆæ¯é…ç½®
        self.extra_message = self.config.get("extra_message", "")

        # é»˜è®¤æç¤ºè¯æ¨¡æ¿
        default_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI è®ºæ–‡è§£è¯»åŠ©æ‰‹ã€‚\n\n"
            "è®ºæ–‡æ ‡é¢˜: {title}\n"
            "ä½œè€…: {authors}\n"
            "æ‘˜è¦: {abstract}\n\n"
            "è®ºæ–‡å†…å®¹ç‰‡æ®µ:\n{full_text}\n\n"
            "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºå…¶ä»–å¯’æš„è¯­ï¼š\n\n"
            "## ğŸ’¡ æ ¸å¿ƒåˆ›æ–°ç‚¹\n(ç®€è¦æ¦‚æ‹¬)\n\n"
            "## ğŸ“– è®ºæ–‡æ¦‚è¦\n(é€šä¿—è§£é‡Šè¿™ç¯‡è®ºæ–‡è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Œç”¨äº†ä»€ä¹ˆæ–¹æ³•)\n\n"
            "## ğŸ‘¥ ä½œè€…èƒŒæ™¯\n(æ ¹æ®ä½œè€…å§“åç®€è¦ä»‹ç»å…¶æ‰€å±æœºæ„æˆ–çŸ¥åä»£è¡¨ä½œï¼Œå¦‚æœæ— æ³•ç¡®å®šåˆ™ç•¥è¿‡)\n\n"
            "## ğŸ”¬ å…³é”®ç»“è®º\n(å®éªŒç»“æœæˆ–ç†è®ºè´¡çŒ®)"
        )
        self.prompt_template = self.config.get("prompt_template", default_prompt)
        
        # åˆå§‹åŒ–è·¯å¾„
        self.plugin_dir = os.path.dirname(__file__)
        self.history_file = os.path.join(self.plugin_dir, "history.json")
        self.temp_dir = os.path.join(self.plugin_dir, "temp")
        if not os.path.exists(self.temp_dir):
            os.makedirs(self.temp_dir)
            
        self.history = self._load_history()
        
        # å®šæ—¶ä»»åŠ¡
        self.scheduler = AsyncIOScheduler()
        try:
            hour, minute = map(int, self.push_time.split(":"))
            self.scheduler.add_job(self.run_daily_push, 'cron', hour=hour, minute=minute)
            self.scheduler.start()
            logger.info(f"AIè®ºæ–‡æ¨é€å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨: {self.push_time}, ç›®æ ‡ç¾¤: {self.target_groups}")
        except Exception as e:
            logger.error(f"å®šæ—¶ä»»åŠ¡å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¶é—´æ ¼å¼(HH:MM): {e}")

    def _parse_target_groups(self, config_str):
        if not config_str:
            return []
        return [g.strip() for g in re.split(r'[,ï¼Œ]', str(config_str)) if g.strip()]

    def _load_history(self):
        if os.path.exists(self.history_file):
            with open(self.history_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []

    def _save_history(self):
        with open(self.history_file, 'w', encoding='utf-8') as f:
            json.dump(self.history, f)

    async def _call_arxiv_api(self, query_url):
        logger.debug(f"Requesting ArXiv: {query_url}, Proxy: {self.proxy}")
        connector = aiohttp.TCPConnector(ssl=False)
        async with aiohttp.ClientSession(connector=connector) as session:
            try:
                async with session.get(query_url, proxy=self.proxy, timeout=30) as response:
                    if response.status != 200:
                        logger.error(f"ArXiv API error: {response.status}")
                        return None
                    data = await response.text()
                    return feedparser.parse(data)
            except Exception as e:
                logger.error(f"Network error fetching arxiv: {e}")
                return None

    async def fetch_latest_paper(self):
        url = "http://export.arxiv.org/api/query?search_query=cat:cs.AI+OR+cat:cs.CV+OR+cat:cs.CL&sortBy=submittedDate&sortOrder=descending&max_results=50"
        feed = await self._call_arxiv_api(url)
        
        if not feed or not feed.entries:
            logger.warning("ArXiv API è¿”å›ä¸ºç©ºæˆ–è§£æå¤±è´¥")
            return None

        for entry in feed.entries:
            paper_id = entry.id.split('/')[-1]
            if paper_id not in self.history:
                return self._parse_entry(entry, paper_id)
        
        logger.warning("æœ€è¿‘ 50 ç¯‡è®ºæ–‡éƒ½å·²æ¨é€è¿‡ã€‚")
        return None

    async def fetch_specific_paper(self, query: str):
        id_pattern = r"(\d{4}\.\d{4,5})"
        match = re.search(id_pattern, query)
        
        url = ""
        if match:
            paper_id = match.group(1)
            url = f"http://export.arxiv.org/api/query?id_list={paper_id}"
        else:
            safe_query = query.replace(" ", "+")
            url = f"http://export.arxiv.org/api/query?search_query=ti:{safe_query}&max_results=1"

        feed = await self._call_arxiv_api(url)
        if not feed or not feed.entries:
            return None
        
        entry = feed.entries[0]
        paper_id = entry.id.split('/')[-1]
        return self._parse_entry(entry, paper_id)

    def _parse_entry(self, entry, paper_id):
        return {
            "id": paper_id,
            "title": entry.title.replace('\n', ' '),
            "summary": entry.summary,
            "authors": [a.name for a in entry.authors],
            "link": entry.link,
            "pdf_link": entry.link.replace("abs", "pdf")
        }

    async def process_pdf(self, pdf_url, paper_id):
        pdf_path = os.path.join(self.temp_dir, f"{paper_id}.pdf")
        img_path = os.path.join(self.temp_dir, f"{paper_id}.png")
        
        connector = aiohttp.TCPConnector(ssl=False)
        async with aiohttp.ClientSession(connector=connector) as session:
            try:
                logger.info(f"Downloading PDF: {pdf_url}")
                async with session.get(pdf_url, proxy=self.proxy, timeout=90) as resp:
                    if resp.status == 200:
                        with open(pdf_path, 'wb') as f:
                            f.write(await resp.read())
                    else:
                        logger.error(f"PDF download status: {resp.status}")
                        return None, None
            except Exception as e:
                logger.error(f"PDF Download failed: {e}")
                return None, None
        
        try:
            doc = fitz.open(pdf_path)
            text_content = ""
            for page in doc[:2]: 
                text_content += page.get_text()
            
            page = doc.load_page(0)
            pix = page.get_pixmap(dpi=150)
            pix.save(img_path)
            doc.close()
            os.remove(pdf_path)
            return text_content, img_path
        except Exception as e:
            logger.error(f"PDF processing failed: {e}")
            return None, None

    async def translate_title(self, title):
        provider = self.context.get_using_provider()
        if not provider:
            return title
        
        try:
            prompt = f"Please translate the following scientific paper title into Chinese. Only output the translated title, do not output anything else.\n\nTitle: {title}"
            response = await provider.text_chat(prompt=prompt)
            cn_title = response.completion_text.strip().strip('"').strip("'")
            return cn_title
        except Exception as e:
            logger.warning(f"Title translation failed: {e}")
            return title

    async def get_ai_summary(self, title, abstract, full_text, authors):
        provider = self.context.get_using_provider()
        if not provider:
            return "é”™è¯¯ï¼šæœªé…ç½® AI æ¨¡å‹ã€‚"
            
        full_text_snippet = full_text[:3000]
        authors_str = ", ".join(authors)
        
        prompt = self.prompt_template.format(
            title=title,
            abstract=abstract,
            full_text=full_text_snippet,
            authors=authors_str
        )
        
        try:
            response = await provider.text_chat(prompt=prompt)
            return response.completion_text
        except Exception as e:
            return f"AI è§£è¯»ç”Ÿæˆå¤±è´¥: {e}"

    async def _broadcast_message(self, message_chain: MessageChain):
        if not self.target_groups:
            return
        platforms = self.context.platform_manager.get_insts()
        adapter = next((p for p in platforms if isinstance(p, AiocqhttpAdapter)), None)
        
        if not adapter:
            logger.error("æœªæ‰¾åˆ° aiocqhttp (QQ) é€‚é…å™¨ï¼Œæ— æ³•å‘é€ç¾¤æ¶ˆæ¯ã€‚")
            return

        for group_id in self.target_groups:
            try:
                logger.info(f"æ­£åœ¨å‘é€åˆ°ç¾¤: {group_id}")
                await AiocqhttpMessageEvent.send_message(
                    bot=adapter.bot,
                    message_chain=message_chain,
                    is_group=True,
                    session_id=group_id
                )
                await asyncio.sleep(2) 
            except Exception as e:
                logger.error(f"å‘é€åˆ°ç¾¤ {group_id} å¤±è´¥: {e}")

    async def _execute_push(self, paper, target_umo=None, is_manual=False, silent_start=False):
        """
        æ‰§è¡Œæ¨é€é€»è¾‘ã€‚
        :param silent_start: æ˜¯å¦é™é»˜å¼€å§‹ï¼ˆä¸å‘é€â€œæ­£åœ¨è·å–...â€ï¼‰
        """
        
        # 1. å‘é€æç¤º
        start_msg = MessageChain([Plain(f"ğŸ“„ æ­£åœ¨è·å–è®ºæ–‡: {paper['title']} ...")])
        
        if is_manual:
            if target_umo:
                await self.context.send_message(target_umo, start_msg)
        elif not silent_start:
            if self.target_groups:
                await self._broadcast_message(start_msg)
        else:
            logger.info(f"æ­£åœ¨åå°å¤„ç†è®ºæ–‡: {paper['title']} ...")

        # 2. å¤„ç†å†…å®¹
        pdf_task = self.process_pdf(paper['pdf_link'], paper['id'])
        trans_task = self.translate_title(paper['title'])
        
        results = await asyncio.gather(pdf_task, trans_task)
        (raw_text, img_path), cn_title = results
        
        if not raw_text or not img_path:
            err_msg = MessageChain([Plain("âš ï¸ PDF ä¸‹è½½æˆ–è§£æå¤±è´¥ã€‚")])
            if is_manual and target_umo:
                await self.context.send_message(target_umo, err_msg)
            elif not is_manual:
                logger.error("PDF å¤„ç†å¤±è´¥")
            return

        # 3. ç”Ÿæˆæ€»ç»“
        explanation = await self.get_ai_summary(paper['title'], paper['summary'], raw_text, paper['authors'])
        
        # 4. è·å– Bot ID
        try:
            self_uin = self.context.platform_manager.get_insts()[0].client_self_id
        except IndexError:
            self_uin = "10000" 

        display_title = f"{cn_title}\n{paper['title']}"

        # Node 1: è®ºæ–‡é¢„è§ˆ
        node1_content: list[BaseMessageComponent] = [
            Plain(f"ğŸ“„ æ ‡é¢˜:\n{display_title}\n\n"),
            Plain(f"ğŸ‘¥ ä½œè€…: {', '.join(paper['authors'][:3])} et al.\n"),
            Plain(f"ğŸ”— é“¾æ¥: {paper['link']}\n"),
            Image.fromFileSystem(img_path)
        ]
        node1 = Node(name="è®ºæ–‡é¢„è§ˆ", uin=self_uin, content=node1_content)
        
        # Node 2: AI è§£è¯»
        node2_content: list[BaseMessageComponent] = [
            Plain(f"è§£è¯»ä¸€ä¸‹~\n\n{explanation}")
        ]
        node2 = Node(name="AI åŠ©æ‰‹", uin=self_uin, content=node2_content)
        
        # 5. ç»„è£… Nodes åˆ—è¡¨
        all_nodes = [node1, node2]

        # Node 3: é¢å¤–æ¶ˆæ¯ (å¦‚æœé…ç½®äº†)
        if self.extra_message and self.extra_message.strip():
            node3_content: list[BaseMessageComponent] = [
                Plain(self.extra_message)
            ]
            node3 = Node(name="è¡¥å……ä¿¡æ¯", uin=self_uin, content=node3_content)
            all_nodes.append(node3)
        
        # 6. å‘é€æ¶ˆæ¯
        try:
            nodes_component = Nodes(all_nodes)
            forward_msg = MessageChain([nodes_component])
            end_msg = MessageChain([Plain("ä»Šæ—¥ AI è®ºæ–‡å·²é€è¾¾~")]) # åç½®æ¶ˆæ¯
            
            if is_manual and target_umo:
                await self.context.send_message(target_umo, forward_msg)
                await asyncio.sleep(1)
                await self.context.send_message(target_umo, end_msg) 
            elif not is_manual:
                await self._broadcast_message(forward_msg)
                await asyncio.sleep(1)
                await self._broadcast_message(end_msg)
            
            if not is_manual:
                self.history.append(paper['id'])
                self._save_history()
                
            if img_path and os.path.exists(img_path):
                os.remove(img_path)
            logger.info("è®ºæ–‡æ¨é€æˆåŠŸ")
                
        except Exception as e:
            logger.error(f"æ¶ˆæ¯å‘é€å¤±è´¥: {e}")
            # é™çº§
            fallback_msg = MessageChain([
                Plain(f"ğŸ“„ {display_title}\n{paper['link']}\n\n"),
                Image.fromFileSystem(img_path),
                Plain(f"\n\n{explanation}")
            ])
            if self.extra_message:
                fallback_msg.chain.append(Plain(f"\n\n{self.extra_message}"))

            if is_manual and target_umo:
                await self.context.send_message(target_umo, fallback_msg)
            elif not is_manual:
                await self._broadcast_message(fallback_msg)

    async def run_daily_push(self):
        """æ¯æ—¥å®šæ—¶ä»»åŠ¡"""
        logger.info(">>> å¼€å§‹æ‰§è¡Œæ¯æ—¥è®ºæ–‡æ¨é€ä»»åŠ¡")
        
        if not self.target_groups:
            logger.warning("æœªé…ç½®æ¨é€ç›®æ ‡ç¾¤ (target_groups)ï¼Œä»»åŠ¡è·³è¿‡ã€‚")
            return
            
        try:
            paper = await self.fetch_latest_paper()
            if not paper:
                logger.warning("æœªè·å–åˆ°æ–°è®ºæ–‡")
                return
            
            await self._execute_push(paper, is_manual=False, silent_start=True)
            
        except Exception as e:
            logger.error(f"å®šæ—¶æ¨é€ä»»åŠ¡å¼‚å¸¸: {e}")

    # --- æŒ‡ä»¤éƒ¨åˆ† ---

    @filter.command("paper_push")
    @filter.permission_type(filter.PermissionType.ADMIN)
    async def push_specific(self, event: AstrMessageEvent, query: str):
        """æ¨é€æŒ‡å®šè®ºæ–‡"""
        if not query:
            yield event.plain_result("è¯·è¾“å…¥è®ºæ–‡é“¾æ¥ã€æ ‡é¢˜æˆ– IDã€‚")
            return

        yield event.plain_result("ğŸ” æ­£åœ¨ ArXiv æ£€ç´¢è®ºæ–‡ä¿¡æ¯...")
        paper = await self.fetch_specific_paper(query)
        
        if not paper:
            yield event.plain_result("âŒ æœªåœ¨ ArXiv ä¸Šæ‰¾åˆ°ç›¸å…³è®ºæ–‡ï¼Œè¯·æ£€æŸ¥è¾“å…¥ã€‚")
            return
            
        target = event.unified_msg_origin
        await self._execute_push(paper, target_umo=target, is_manual=True)

    @filter.command("paper_push_now")
    @filter.permission_type(filter.PermissionType.ADMIN)
    async def push_now(self, event: AstrMessageEvent):
        """ç«‹å³è§¦å‘è‡ªåŠ¨æ¨é€"""
        paper = await self.fetch_latest_paper()
        if not paper:
            yield event.plain_result("æ²¡æœ‰è·å–åˆ°æ–°çš„å¾…æ¨é€è®ºæ–‡ã€‚")
            return
            
        await self._execute_push(paper, target_umo=event.unified_msg_origin, is_manual=True, silent_start=False)